{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a python script which is a replicated MapBasic code from a file named **BusLines_Frequency_F6.MBX** \n",
    "\n",
    "\n",
    "_Important Note: Python v3.9.1 is needed since it comes compiled with SQLite version 3.33.0. This version of SQLite has introduced some new SQL JOIN statements which are used in the script._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create folder structure:**\n",
    "\n",
    "```\n",
    "D:\\Routelines\n",
    "        \\data\n",
    "        \\db\n",
    "        \\rlc\n",
    "        \\shp\n",
    "\n",
    "\\data -> put here \"NOCTable.csv\" and CIF files in subfolders by region\n",
    "\\db   -> here will be created sqlite db file\n",
    "\\rlc  -> here will be the files related to \"Route Line Creator\" (input CSV and output result)\n",
    "\\shp  -> here will be created final shapefile\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"D:/Routelines/\"\n",
    "cif_path = project + 'data/'\n",
    "db_path = project + 'db/'\n",
    "rlc_input_path = project + 'rlc/'\n",
    "\n",
    "RegionID = ['EA'] #,'W','NE','EM','WM','SW','Y','NW','S','SE','L']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python v3.9.2 (tags/v3.9.2:1a79785, Feb 19 2021, 13:44:55) [MSC v.1928 64 bit (AMD64)]\n",
      "------------------------------------------------------------------------------\n",
      "Pandas v1.2.4\n",
      "NumPy v1.19.4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "import io\n",
    "import psycopg2\n",
    "\n",
    "import math\n",
    "import mmap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print('Python v' + sys.version)\n",
    "print('------------------------------------------------------------------------------')\n",
    "print('Pandas v' + pd.__version__)\n",
    "print('NumPy v' + np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### global variables definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import click\n",
    "import configparser\n",
    "\n",
    "# instantiate\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "# parse existing file\n",
    "config.read('setup.ini')\n",
    "\n",
    "# read values from a section DATABASE\n",
    "db_server = config.get('database', 'db_server')\n",
    "db_port = config.getint('database', 'db_port')\n",
    "db_def = config.get('database', 'db_def')\n",
    "db_name = config.get('database', 'db_name')\n",
    "db_schema = config.get('database', 'db_schema')\n",
    "db_user = config.get('database', 'db_user')\n",
    "db_password = config.get('database', 'db_password')\n",
    "\n",
    "# read values from a section PROJECT\n",
    "version = config.get('project', 'version')\n",
    "dir_prj = config.get('project', 'dir_prj')\n",
    "dir_cif = config.get('project', 'dir_cif')\n",
    "cif_file = config.get('project', 'cif_file')\n",
    "pts_table = config.get('project', 'pts_table')\n",
    "\n",
    "def config_read(ini_filename, section, value):\n",
    "\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(ini_filename)\n",
    "    \n",
    "    return config.get(section, value)\n",
    "\n",
    "def config_print(ini_filename):\n",
    "\n",
    "    print(95*\"-\")\n",
    "    print(\"Current configuration\")\n",
    "    print(\"Project data folder   : \", dir_prj)\n",
    "    print(\"CIF data folder       : \", dir_cif)\n",
    "    print(\"CIF file              : \", cif_file)\n",
    "    print(\"PTStops tablename     : \", pts_table)\n",
    "    print(95*\"-\")\n",
    "    print(\"db server   : \", db_server)\n",
    "    print(\"db port     : \", db_port)\n",
    "    print(\"db default  : \", db_def)\n",
    "    print(\"database    : \", db_name)\n",
    "    print(\"schema      : \", db_schema)\n",
    "    print(\"user        : \", db_user)\n",
    "    print(\"password    : \", db_password)\n",
    "    print(95*\"-\")\n",
    "\n",
    "def config_write(ini_filename):\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(ini_filename)\n",
    "\n",
    "    print(\"Set database parameters (ENTER for default values):\")\n",
    "    print(23*\"-\")\n",
    "    \n",
    "    db_server = click.prompt(\"db_server: \", type=str, default='localhost')\n",
    "    config.set('database', 'db_server', db_server)\n",
    "\n",
    "    db_port = click.prompt(\"db port: \", type=str, default='5434')\n",
    "    config.set('database', 'db_port', db_port)\n",
    "\n",
    "    db_def = click.prompt(\"db def: \", type=str, default='postgres')\n",
    "    config.set('database', 'db_def', db_def)\n",
    "\n",
    "    db_name = click.prompt(\"db name: \", type=str, default='routelinesuk')\n",
    "    config.set('database', 'db_name', db_name)\n",
    "\n",
    "    db_schema = click.prompt(\"db schema: \", type=str, default='rl')\n",
    "    config.set('database', 'db_schema', db_schema)\n",
    "\n",
    "    db_user = click.prompt(\"db user: \", type=str, default='postgres')\n",
    "    config.set('database', 'db_user', db_user)\n",
    "\n",
    "    db_password = click.prompt(\"db password: \", type=str, default='softdesk')\n",
    "    config.set('database', 'db_password', db_password)\n",
    "\n",
    "    print(\"Set project file management parameters:\")\n",
    "    print(38*\"-\")\n",
    "\n",
    "    dir_prj = click.prompt(\"Project data main folder: \", type=str, default='D:/Routelines')\n",
    "    config.set('project', 'dir_prj', dir_prj)\n",
    "\n",
    "    dir_cif = click.prompt(\"CIF data folder: \", type=str, default='D:/Routelines/data/')\n",
    "    config.set('project', 'dir_cif', dir_cif)\n",
    "\n",
    "    cif_file = click.prompt(\"CIF filename: \", type=str, default='Bus_1.cif')\n",
    "    config.set('project', 'cif_file', cif_file)\n",
    "\n",
    "    try:\n",
    "        with open(ini_filename, 'w') as configfile:\n",
    "            config.write(configfile)\n",
    "    except IOError:\n",
    "        print(f\"Unable to create {ini_filename} file!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from getpass import getpass\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.schema import CreateSchema\n",
    "from sqlalchemy_utils import database_exists\n",
    "\n",
    "\n",
    "def db_connect(db_server, db_port, dbname, db_user, db_password):\n",
    "\n",
    "    # db_password = getpass(f\"Please enter password for user {db_user} @ database {dbname}:\")\n",
    "\n",
    "    # db connection:\n",
    "    engine = create_engine(f\"postgresql+psycopg2://{db_user}:{db_password}@{db_server}:{db_port}/{dbname}\")\n",
    "\n",
    "    if database_exists(engine.url):\n",
    "        db_status = f\"Successfully connected to database '{dbname}' on server '{db_server}' !\"\n",
    "        print(db_status)\n",
    "        return engine\n",
    "    else:\n",
    "        db_status = f\"Could not connect to '{dbname}' database on server '{db_server}'!\\n\"\\\n",
    "                    \"Please check if database exist or if configuration parameters are correct.\"\n",
    "        print(db_status)\n",
    "        return 0\n",
    "\n",
    "\n",
    "def connect(db_name, db_user, db_password, db_server, db_port):\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # connect to the PostgreSQL server\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        conn = psycopg2.connect(dbname=db_name, user=db_user, password=db_password, host=db_server, port=db_port)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        sys.exit(1) \n",
    "    print(\"Connection successful\")\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.  CIF data extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noc_table(conn, dir_cif):\n",
    "    NOCTable = pd.read_csv(dir_cif + 'NOCTable.csv')\n",
    "    NOCTable.to_sql('noctable', conn, schema='rl', if_exists='replace', index = False, chunksize = 100000)\n",
    "    conn.execute('''CREATE UNIQUE INDEX noccode_idx ON rl.noctable USING btree (\"NOCCODE\" text_pattern_ops ASC NULLS LAST) TABLESPACE pg_default''')\n",
    "    conn.execute(\"COMMIT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapcount(filename):\n",
    "    print(\"Counting number of lines...\")\n",
    "    f = open(filename, \"r+\")\n",
    "    buf = mmap.mmap(f.fileno(), 0)\n",
    "    lines = 0\n",
    "    readline = buf.readline\n",
    "    while readline():\n",
    "        lines += 1\n",
    "    print(f'{lines} lines in the file!')\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_with_progress(conn, df, tablename):\n",
    "    chunksize = int(len(df) / 10) # 10%\n",
    "    with tqdm(total=len(df)) as pbar:\n",
    "        for i, cdf in enumerate(chunker(df, chunksize)):\n",
    "            cdf.to_sql(tablename, conn, schema='rl', if_exists='append', index=False, method='multi') \n",
    "            pbar.update(chunksize)\n",
    "            pbar.set_description(f'Inserting to database...')\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reading CIF file\n",
    "\n",
    "def read_cif(cif_file):\n",
    "    print(95*\"-\")\n",
    "    print(f'CIF file size is {round(os.stat(cif_file).st_size / (1024 * 1024), 2)} MB')   \n",
    "    count_lines = mapcount(cif_file)\n",
    "    chunk_size=1000000\n",
    "    chunks = []\n",
    "    loops = math.ceil(count_lines/chunk_size)\n",
    "    i=0\n",
    "    with tqdm(total = loops, file = sys.stdout) as pbar:\n",
    "        reader = pd.read_csv(cif_file, names=['CODE'], header=None, sep='!', iterator=True)\n",
    "        while i <= loops:\n",
    "            try:\n",
    "                i+=1\n",
    "                chunk = reader.get_chunk(chunk_size)\n",
    "                chunks.append(chunk)\n",
    "                pbar.set_description('Importing CIF data to Pandas dataframe')\n",
    "                pbar.update(1)\n",
    "            except StopIteration:\n",
    "                loop = False\n",
    "                cif_data = pd.concat(chunks, ignore_index=True)\n",
    "                pbar.update(1)\n",
    "    pbar.close()\n",
    "    print(\"CIF data imported!\")\n",
    "    return cif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PTStops table creation\n",
    "\n",
    "def GetPtStops(conn, cif_data, tablename):\n",
    "    print(\"Extracting QB nodes in progress...\")\n",
    "    QB = cif_data['CODE'].str.extract('(^QB.*)').dropna()\n",
    "    QB.columns = ['CODE']\n",
    "    print(\"QB nodes extracted:\", len(QB))\n",
    "    COLUMN_NAMES = ['naptanid','xcoord','ycoord']\n",
    "    PTStops = pd.DataFrame(columns=COLUMN_NAMES)\n",
    "    PTStops['naptanid'] = QB['CODE'].str.slice(start=3, stop=15).str.rstrip()\n",
    "    PTStops['xcoord'] = QB['CODE'].str.slice(start=15, stop=21)\n",
    "    PTStops['ycoord'] = QB['CODE'].str.slice(start=23, stop=29)\n",
    "    # convert columns \"xcoord\" and \"ycoord\" to numeric\n",
    "    PTStops[[\"xcoord\", \"ycoord\"]] = PTStops[[\"xcoord\", \"ycoord\"]].apply(pd.to_numeric, downcast='integer')\n",
    "    insert_with_progress(conn, PTStops, tablename)\n",
    "    conn.execute('''CREATE INDEX ptstops_idx ON rl.ptstops USING btree (naptanid text_pattern_ops ASC NULLS LAST) TABLESPACE pg_default''')\n",
    "    conn.execute(\"COMMIT\")\n",
    "    return PTStops  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Routes extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_from_stringio_progress(conn, df, table, cols):\n",
    "    \"\"\"\n",
    "    Here we are going save the dataframe in memory and use copy_from() to copy it to the table\n",
    "    \"\"\"\n",
    "    # save dataframe to an in memory buffer\n",
    "    buffer = io.StringIO()\n",
    "    df.to_csv(buffer, index_label='id', header=False)\n",
    "    buffer.seek(0)\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    count_lines=df.shape[0]\n",
    "    chunk_size=1000000\n",
    "    chunks = []\n",
    "    loops = math.ceil(count_lines/chunk_size)\n",
    "    i=0\n",
    "\n",
    "    with tqdm(total = loops, file = sys.stdout) as pbar:\n",
    "        while i <= loops:\n",
    "            try:\n",
    "                i+=1\n",
    "                reader = cursor.copy_from(buffer, table, sep=\",\", columns=cols )\n",
    "                conn.commit()\n",
    "                pbar.set_description('Uploading to PostgreSQL...')\n",
    "                pbar.update(1)\n",
    "            except (Exception, psycopg2.DatabaseError) as error:\n",
    "                print(\"Error: %s\" % error)\n",
    "                conn.rollback()\n",
    "                cursor.close()\n",
    "                return 1\n",
    "    pbar.close()\n",
    "    print(f\"Uploading '{table}' to PostgreSQL done!\")\n",
    "    cursor.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_from_stringio(conn, df, table, cols):\n",
    "    \"\"\"\n",
    "    Here we are going save the dataframe in memory and use copy_from() to copy it to the table\n",
    "    \"\"\"\n",
    "    # save dataframe to an in memory buffer\n",
    "    buffer = io.StringIO()\n",
    "    df.to_csv(buffer, index_label='id', header=False)\n",
    "    buffer.seek(0)\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.copy_from(buffer, table, sep=\",\", columns=cols )\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    print(f\"Uploading '{table}' to PostgreSQL done!\")\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetRouteDataToSQL(conn, conn2, cif_df, region):\n",
    "    \n",
    "    # temp list for RouteLines1 columns\n",
    "\n",
    "    l_Region = []\n",
    "    l_BMRouteID_1 = []\n",
    "    l_BM_StartStopID_1 = []\n",
    "    l_AnodeStopID = []\n",
    "    l_BnodeStopID = []\n",
    "    l_AnodeXcoord = []\n",
    "    l_AnodeYcoord = []\n",
    "    l_BnodeXcoord = []\n",
    "    l_BnodeYcoord = []\n",
    "    # l_id_1 = []\n",
    "\n",
    "    # temp list for MainTable columns\n",
    "\n",
    "    l_OperatorCode = []\n",
    "    l_ServiceNum = []\n",
    "    l_BM_RouteID_2 = []\n",
    "    l_BM_StartStopID_2 = []\n",
    "    l_Direction = []\n",
    "    l_StopID = []\n",
    "    l_DeptTime = []\n",
    "    l_Seq = []\n",
    "    l_Mon = []\n",
    "    l_Tue = []\n",
    "    l_Wed = []\n",
    "    l_Thu = []\n",
    "    l_Fri = []\n",
    "    l_Sat = []\n",
    "    l_Sun = []\n",
    "    l_TotalWeekly = []\n",
    "    # l_id_2 = []\n",
    "\n",
    "    # routelines1 to PostgreSQL\n",
    "\n",
    "    conn.execute('''DROP TABLE IF EXISTS rl.routelines1''')\n",
    "    conn.execute(\"COMMIT\")\n",
    "    conn.execute('''CREATE TABLE rl.routelines1 ( id integer PRIMARY KEY,\n",
    "                                                  region text,\n",
    "                                                  bmrouteid text,\n",
    "                                                  bm_startstopid text,\n",
    "                                                  anodestopid text,\n",
    "                                                  bnodestopid text,\n",
    "                                                  anodexcoord text,\n",
    "                                                  anodeycoord text,\n",
    "                                                  bnodexcoord text,\n",
    "                                                  bnodeycoord text) TABLESPACE pg_default'''\n",
    "                                                  )\n",
    "    conn.execute(\"COMMIT\")\n",
    "    conn.execute('ALTER TABLE rl.routelines1 OWNER to postgres')\n",
    "    conn.execute(\"COMMIT\")\n",
    "    # conn.execute('''CREATE INDEX rl1_bm_startstopid_idx ON rl.routelines1 USING btree (bm_startstopid text_pattern_ops ASC NULLS LAST) TABLESPACE pg_default''')\n",
    "    # conn.execute(\"COMMIT\")\n",
    "    # conn.execute('''CREATE INDEX rl1_bmrouteid_idx ON rl.routelines1 USING btree (bmrouteid text_pattern_ops ASC NULLS LAST) TABLESPACE pg_default''')\n",
    "    # conn.execute(\"COMMIT\")\n",
    "\n",
    "    # maintable to PostgreSQL\n",
    "\n",
    "    conn.execute('''DROP TABLE IF EXISTS rl.maintable''')\n",
    "    conn.execute(\"COMMIT\")    \n",
    "    conn.execute('''CREATE TABLE rl.maintable( id integer PRIMARY KEY,\n",
    "                                               operatorcode text,\n",
    "                                               servicenum text,\n",
    "                                               bm_routeid text,\n",
    "                                               bm_startstopid text,\n",
    "                                               direction text,\n",
    "                                               stopid text,\n",
    "                                               depttime integer,\n",
    "                                               seq integer,\n",
    "                                               mon integer,\n",
    "                                               tue integer,\n",
    "                                               wed integer,\n",
    "                                               thur integer,\n",
    "                                               fri integer,\n",
    "                                               sat integer,\n",
    "                                               sun integer,\n",
    "                                               totalweekly integer) TABLESPACE pg_default'''\n",
    "                                               )\n",
    "    conn.execute(\"COMMIT\")\n",
    "    conn.execute('ALTER TABLE rl.maintable OWNER to postgres')\n",
    "    conn.execute(\"COMMIT\")\n",
    "    # conn.execute('''CREATE INDEX mt_bm_startstopid_idx ON rl.maintable USING btree (bm_startstopid text_pattern_ops ASC NULLS LAST)  TABLESPACE pg_default''')\n",
    "    # conn.execute(\"COMMIT\")    \n",
    "    # conn.execute('''CREATE INDEX mt_bm_routeid_idx ON rl.maintable USING btree (bm_routeid text_pattern_ops ASC NULLS LAST) TABLESPACE pg_default''')\n",
    "    # conn.execute(\"COMMIT\")    \n",
    "#   -----------\n",
    "    print(\"Data extraction from CIF to lists...\")\n",
    "    \n",
    "    BankHolOnly = \"\" \n",
    "\n",
    "    for x in cif_df['CODE']:\n",
    "        if x[0:2]=='QS':\n",
    "    #         -----------------------\n",
    "    #         QS\n",
    "    #         -----------------------\n",
    "            SeqNo = 0\n",
    "            AnodeStr = \"XXXX\"\n",
    "            RouteIDFull = x[38:65]\n",
    "    #         print(\"1-\",RouteIDFull)\n",
    "            RouteIDV = RouteIDFull[:4].rstrip()\n",
    "    #         print(\"2-\",RouteIDV)\n",
    "            RouteIDFull = x[37:65]\n",
    "    #         print(\"3-\",RouteIDFull)        \n",
    "            BankHolOnly = RouteIDFull[0]\n",
    "    #         print(\"4-\",BankHolOnly)\n",
    "            if BankHolOnly != \"\":\n",
    "                pass\n",
    "            RouteIDFull =x[3:]\n",
    "    #         print(\"5-\"+RouteIDFull)                \n",
    "            RouteOpV = RouteIDFull[:4].rstrip()\n",
    "    #         print(\"6-\"+RouteOpV)\n",
    "            ServiceIDv = RouteIDV\n",
    "            RouteIDFull = x[64:]\n",
    "    #         print(\"7-\"+RouteIDFull)        \n",
    "            DirectionV = RouteIDFull[0]\n",
    "    #       RouteIDV = region + \"_\" + RouteOpV + \"_\" +  RouteIDV + \"_\" + DirectionV\n",
    "            RouteIDV = RouteOpV + \"_\" +  RouteIDV + \"_\" + DirectionV\n",
    "    #         print(\"8-\"+RouteIDV)\n",
    "    #         RouteIDFull = x[29:]\n",
    "            MonV = int(x[29:][0])\n",
    "    #         print(\"MonV =\", MonV)\n",
    "            TueV = int(x[30:][0])\n",
    "    #         print(\"TueV =\", TueV)\n",
    "            WedV = int(x[31:][0])\n",
    "    #         print(\"WedV =\", WedV)\n",
    "            ThuV = int(x[32:][0])\n",
    "    #         print(\"ThuV =\", ThuV)\n",
    "            FriV = int(x[33:][0])\n",
    "    #         print(\"FriV =\", FriV)\n",
    "            SatV = int(x[34:][0])\n",
    "    #         print(\"SatV =\", SatV)\n",
    "            SunV = int(x[35:][0])\n",
    "    #         print(\"SunV =\", SunV)\n",
    "    #         print(\"------------\")\n",
    "        if BankHolOnly == \"B\":\n",
    "            BankLoop = BankLoop + 1\n",
    "            if BankLoop == 1:\n",
    "                print(\"WARNING: Bank holiday services exist!\")\n",
    "        else:\n",
    "            if x[0:2] in ('QO','QI','QT'):\n",
    "    #             print(x[0:2])\n",
    "    #             -----------------------\n",
    "    #             QO / QI / QT\n",
    "    #             -----------------------\n",
    "                RouteIDFull = x[2:]\n",
    "    #             print(\"9 -\", RouteIDFull)\n",
    "                RSStopID = RouteIDFull[:12].rstrip()\n",
    "    #             print(\"10-\", RSStopID)\n",
    "                StopArea = RouteIDFull[:4].rstrip()\n",
    "                BnodeStr = RSStopID\n",
    "    #             print(\"StopArea -\",StopArea)\n",
    "    #             print(\"BnodeStr -\",BnodeStr)\n",
    "                RouteIDFull = x[14:]\n",
    "    #             print(\"11-\", RouteIDFull)\n",
    "                TimeNum = RouteIDFull[:4]\n",
    "    #             print(\"12-\", TimeNum)\n",
    "                SeqNo = SeqNo + 1\n",
    "                if SeqNo == 1:\n",
    "                    StartStopID = RSStopID\n",
    "                if SeqNo > 1:\n",
    "                    # print(\"RouteLines1:\")\n",
    "                    l_Region.append(region)\n",
    "                    l_BMRouteID_1.append(RouteIDV)\n",
    "                    l_BM_StartStopID_1.append(StartStopID)\n",
    "                    l_AnodeStopID.append(AnodeStr)\n",
    "                    l_BnodeStopID.append(BnodeStr)\n",
    "                    l_AnodeXcoord.append(0)\n",
    "                    l_AnodeYcoord.append(0)\n",
    "                    l_BnodeXcoord.append(0)\n",
    "                    l_BnodeYcoord.append(0)\n",
    "                    # l_id_1.append(SeqNo)\n",
    "                AnodeStr = RSStopID\n",
    "                if int(TimeNum) >= 0 and int(TimeNum) < 2400:\n",
    "                    # print(\"MainTable:\")\n",
    "                    l_OperatorCode.append(RouteOpV)\n",
    "                    l_ServiceNum.append(ServiceIDv)\n",
    "                    l_BM_RouteID_2.append(RouteIDV)\n",
    "                    l_BM_StartStopID_2.append(StartStopID)\n",
    "                    l_Direction.append(DirectionV)\n",
    "                    l_StopID.append(RSStopID)\n",
    "                    l_DeptTime.append(TimeNum)\n",
    "                    l_Seq.append(SeqNo)\n",
    "                    l_Mon.append(MonV)\n",
    "                    l_Tue.append(TueV)\n",
    "                    l_Wed.append(WedV)\n",
    "                    l_Thu.append(ThuV)\n",
    "                    l_Fri.append(FriV)\n",
    "                    l_Sat.append(SatV)\n",
    "                    l_Sun.append(SunV)\n",
    "                    l_TotalWeekly.append(0) \n",
    "                    # l_id_2.append(SeqNo)\n",
    "    \n",
    "#   -----------\n",
    "# Pandas dataframe creations\n",
    "\n",
    "    # - RouteLines1\n",
    "    print(\"Loading RouteLines1 to Pandas dataframe...\")\n",
    "    \n",
    "    RouteLines1 = pd.DataFrame(\n",
    "        {'region':l_Region,\n",
    "         'bmrouteid':l_BMRouteID_1,\n",
    "         'bm_startstopid':l_BM_StartStopID_1,\n",
    "         'anodestopid':l_AnodeStopID,\n",
    "         'bnodestopid':l_BnodeStopID,\n",
    "         'anodexcoord':l_AnodeXcoord ,\n",
    "         'anodeycoord':l_AnodeYcoord ,\n",
    "         'bnodexcoord':l_BnodeXcoord ,\n",
    "         'bnodeycoord':l_BnodeYcoord\n",
    "        #  ,\n",
    "        #  'id':l_id_1\n",
    "        })\n",
    "    \n",
    "\n",
    "    # - MainTable\n",
    "    print(\"Loading MainTable to Pandas dataframe...\")\n",
    "    \n",
    "    MainTable = pd.DataFrame(\n",
    "        {'operatorcode':l_OperatorCode,\n",
    "         'servicenum':l_ServiceNum,\n",
    "         'bm_routeid':l_BM_RouteID_2,\n",
    "         'bm_startstopid':l_BM_StartStopID_2,\n",
    "         'direction':l_Direction,\n",
    "         'stopid':l_StopID,\n",
    "         'depttime':l_DeptTime,\n",
    "         'seq':l_Seq,\n",
    "         'mon':l_Mon,\n",
    "         'tue':l_Tue,\n",
    "         'wed':l_Wed,\n",
    "         'thur':l_Thu,\n",
    "         'fri':l_Fri,\n",
    "         'sat':l_Sat,\n",
    "         'sun':l_Sun,\n",
    "         'totalweekly':l_TotalWeekly\n",
    "        #  ,\n",
    "        #  'id':l_id_2\n",
    "        })\n",
    "    \n",
    "    print(f\"RouteLines1 size: {len(RouteLines1.index)} rows\")\n",
    "    print(f\"MainTable size:   {len(MainTable.index)} rows\")\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------------------------\n",
    "    # EMPTY temp list for RouteLines1 columns\n",
    "\n",
    "    l_Region = []\n",
    "    l_BMRouteID_1 = []\n",
    "    l_BM_StartStopID_1 = []\n",
    "    l_AnodeStopID = []\n",
    "    l_BnodeStopID = []\n",
    "    l_AnodeXcoord = []\n",
    "    l_AnodeYcoord = []\n",
    "    l_BnodeXcoord = []\n",
    "    l_BnodeYcoord = []\n",
    "    # l_id_1 = []\n",
    "\n",
    "    # EMPTY temp list for MainTable columns\n",
    "\n",
    "    l_OperatorCode = []\n",
    "    l_ServiceNum = []\n",
    "    l_BM_RouteID_2 = []\n",
    "    l_BM_StartStopID_2 = []\n",
    "    l_Direction = []\n",
    "    l_StopID = []\n",
    "    l_DeptTime = []\n",
    "    l_Seq = []\n",
    "    l_Mon = []\n",
    "    l_Tue = []\n",
    "    l_Wed = []\n",
    "    l_Thu = []\n",
    "    l_Fri = []\n",
    "    l_Sat = []\n",
    "    l_Sun = []\n",
    "    l_TotalWeekly = []    \n",
    "    # l_id_2 = []\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------------------------\n",
    "    #  Upload to db\n",
    "\n",
    "    print(\"Uploading RouteLines1 df to PostgreSQL...\")    \n",
    "    # RouteLines1.to_sql('routelines1', conn, schema='rl' ,if_exists='append', method='multi', index = False) # SLOW!\n",
    "    copy_from_stringio_progress(conn2, RouteLines1, 'rl.routelines1', ('id','region', 'bmrouteid', 'bm_startstopid', 'anodestopid', 'bnodestopid', 'anodexcoord', 'anodeycoord', 'bnodexcoord', 'bnodeycoord'))\n",
    "        \n",
    "    print(\"Uploading MainTable df to PostgreSQL...\")    \n",
    "    # MainTable.to_sql('maintable', conn, schema='rl' ,if_exists='append', method='multi', index = False) # SLOW!\n",
    "    copy_from_stringio_progress(conn2, MainTable, 'rl.maintable', ('id','operatorcode','servicenum','bm_routeid','bm_startstopid','direction','stopid','depttime','seq','mon','tue','wed','thur','fri','sat','sun','totalweekly'))\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ptstops_update(conn):\n",
    "\n",
    "    print(\"Updating 'PTStops_temp'...\")\n",
    "    \n",
    "    conn.execute('''INSERT INTO rl.ptstops_temp (naptanid, xcoord, ycoord) SELECT naptanid, xcoord, ycoord FROM rl.ptstops GROUP BY naptanid, xcoord, ycoord''')    \n",
    "    conn.execute(\"COMMIT\")\n",
    "    conn.execute('''CREATE INDEX ptstops_tmp_idx ON rl.ptstops_temp USING btree (naptanid text_pattern_ops ASC NULLS LAST) TABLESPACE pg_default''')\n",
    "    conn.execute(\"COMMIT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rl1_update(conn):    \n",
    "\n",
    "    print(\"Updating RouteLines1 RouteID ...\")\n",
    "    \n",
    "    conn.execute('''UPDATE rl.routelines1 \n",
    "                    SET bmrouteid = bmrouteid || '_' || LEFT(tmp.xcoord,3) || '_' || LEFT(tmp.ycoord,3) \n",
    "                    FROM rl.ptstops_temp tmp\n",
    "                    WHERE bm_startstopid = tmp.naptanid''')\n",
    "    conn.execute(\"COMMIT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mt_update(conn):    \n",
    "\n",
    "    print(\"Updating Maintable RouteID...\")\n",
    "    \n",
    "    conn.execute('''UPDATE rl.maintable \n",
    "                    SET bm_routeid = bm_routeid || '_' || LEFT(tmp.xcoord,3) || '_' || LEFT(tmp.ycoord,3) \n",
    "                    FROM rl.ptstops_temp tmp\n",
    "                    WHERE bm_startstopid = tmp.naptanid''')\n",
    "    conn.execute(\"COMMIT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. CreateFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TempGetFreq(conn, ColName, depttime1, depttime2):\n",
    "    conn.execute('''CREATE TABLE rl.tempgetfreq AS SELECT * FROM rl.maintable WHERE ''' + ColName + ''' = 1 AND depttime >= ''' + str(depttime1) + ''' AND depttime < ''' + str(depttime2) + ''' AND seq = 1''')\n",
    "    conn.execute(\"COMMIT\")\n",
    "    conn.execute('''CREATE TABLE rl.sumfreq AS SELECT bm_routeid, SUM(seq) AS sumfreq FROM rl.tempgetfreq GROUP BY bm_routeid''')\n",
    "    conn.execute(\"COMMIT\")\n",
    "    \n",
    "def UpdFreqVal(conn, UpdCol, round_value):\n",
    "    conn.execute('''UPDATE rl.rlfreq SET ''' + UpdCol + ''' = updfreqval.sumfreq/''' + str(round_value) + '''\n",
    "                    FROM (SELECT rl.rlfreq.bm_routeid, operatorcode, servicenum, direction, operatorname,\n",
    "                                monearly, monam, monbp, monep, monop, monnight,\n",
    "                                tueearly, tueam, tuebp, tueep, tueop, tuenight, \n",
    "                                wedearly, wedam, wedbp, wedep, wedop, wednight,\n",
    "                                thurearly, thuram, thurbp, thurep, thurop, thurnight,\n",
    "                                friearly, friam, fribp, friep, friop, frinight,\n",
    "                                satearly, satam, satbp, satep, satop, satnight, \n",
    "                                sunearly, sunam, sunbp, sunep, sunop, sunnight, \n",
    "                                id, sumfreq \n",
    "                        FROM rl.rlfreq, rl.sumfreq \n",
    "                        WHERE rl.rlfreq.bm_routeid = sumfreq.bm_routeid) AS updfreqval \n",
    "                    WHERE rl.rlfreq.id = updfreqval.id''')\n",
    "    conn.execute(\"COMMIT\")\n",
    "    conn.execute('''UPDATE rl.rlfreq SET ''' + UpdCol + ''' = 0 WHERE ''' + UpdCol + ''' is NULL''')\n",
    "    conn.execute(\"COMMIT\")\n",
    "    conn.execute('''UPDATE rl.rlfreq SET ''' + UpdCol + ''' = ROUND(CAST(''' + UpdCol + ''' AS numeric), 2)''')\n",
    "    conn.execute(\"COMMIT\")\n",
    "    conn.execute('''DROP TABLE IF EXISTS rl.tempgetfreq''')\n",
    "    conn.execute(\"COMMIT\")\n",
    "    conn.execute('''DROP TABLE IF EXISTS rl.sumfreq''')\n",
    "    conn.execute(\"COMMIT\")\n",
    "\n",
    "def CreateFreq(conn):\n",
    "    \n",
    "    ColNames = {1:'mon', 2:'tue', 3:'wed', 4:'thur', 5:'fri', 6:'sat', 7:'sun'}\n",
    "    \n",
    "    DepTimes = {\n",
    "                'am':[2.0, 700,900],\n",
    "                'bp':[7.0, 900,1600],\n",
    "                'ep':[2.0, 1600,1800],\n",
    "                'op':[6.0, 1800,2400],\n",
    "                'night':[3.0, 0,300],\n",
    "                'early':[3.0, 400,700]\n",
    "               }    \n",
    "    conn.execute('''DROP TABLE IF EXISTS rl.rlfreq''')    \n",
    "    conn.execute(\"COMMIT\")\n",
    "    conn.execute('''CREATE TABLE rl.rlfreq(\n",
    "       bm_routeid    text,\n",
    "       operatorcode  text,\n",
    "       servicenum    text,\n",
    "       direction     text,\n",
    "       operatorname  text,\n",
    "       monearly      real,\n",
    "       monam         real,\n",
    "       monbp         real,\n",
    "       monep         real,\n",
    "       monop         real,\n",
    "       monnight      real,\n",
    "       tueearly      real,\n",
    "       tueam         real,\n",
    "       tuebp         real,\n",
    "       tueep         real,\n",
    "       tueop         real,\n",
    "       tuenight      real,\n",
    "       wedearly      real,\n",
    "       wedam         real,\n",
    "       wedbp         real,\n",
    "       wedep         real,\n",
    "       wedop         real,\n",
    "       wednight      real,\n",
    "       thurearly     real,\n",
    "       thuram        real,\n",
    "       thurbp        real,\n",
    "       thurep        real,\n",
    "       thurop        real,\n",
    "       thurnight     real,\n",
    "       friearly      real,\n",
    "       friam         real,\n",
    "       fribp         real,\n",
    "       friep         real,\n",
    "       friop         real,\n",
    "       frinight      real,\n",
    "       satearly      real,\n",
    "       satam         real,\n",
    "       satbp         real,\n",
    "       satep         real,\n",
    "       satop         real,\n",
    "       satnight      real,\n",
    "       sunearly      real,\n",
    "       sunam         real,\n",
    "       sunbp         real,\n",
    "       sunep         real,\n",
    "       sunop         real,\n",
    "       sunnight      real,\n",
    "       id serial PRIMARY KEY) TABLESPACE pg_default''')\n",
    "    \n",
    "    conn.execute('''\n",
    "                    INSERT INTO rl.rlfreq (bm_routeid, operatorcode, servicenum, direction)\n",
    "                    SELECT bm_routeid, operatorcode, servicenum, direction\n",
    "                    FROM rl.maintable \n",
    "                    GROUP BY bm_routeid, operatorcode, servicenum, direction \n",
    "                    ORDER BY bm_routeid\n",
    "                    ''')\n",
    "    conn.execute(\"COMMIT\")\n",
    "\n",
    "    conn.execute('''UPDATE rl.rlfreq \n",
    "                    SET operatorname = \"OperatorPublicName\"\n",
    "                    FROM (SELECT * From rl.rlfreq, rl.noctable WHERE operatorcode = \"NOCCODE\" AND NOT operatorcode = '') AS updop\n",
    "                    WHERE updop.id = rl.rlfreq.id''')\n",
    "    conn.execute(\"COMMIT\")\n",
    "    \n",
    "    for key1, value1 in ColNames.items():\n",
    "        print(\"Freq. Calculations for \" + value1 + \"...\")\n",
    "        for key2, value2 in DepTimes.items():\n",
    "    #       print(key1, \"ColName=\" + str(value1+key2), value2[0],value2[1],value2[2])\n",
    "    #       print(\"TempGetFreq\", str(value1), value2[1], value2[2])\n",
    "            TempGetFreq(conn, str(value1), value2[1], value2[2])\n",
    "    #       print(\"UpdFreqVal\", str(value1+key2), value2[0])\n",
    "            UpdFreqVal(conn, str(value1+key2), value2[0])    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. ABSorter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ABsorter(conn):\n",
    "    \n",
    "    print(\"Creation of ABNodes and updating...\")\n",
    "    \n",
    "    conn.execute('''DROP TABLE IF EXISTS rl.abnodes;''')\n",
    "    conn.execute(\"COMMIT\")\n",
    "    conn.execute('''CREATE TABLE rl.abnodes(\n",
    "                                            anodestopid text ,\n",
    "                                            bnodestopid text ,\n",
    "                                            anodexcoord integer,\n",
    "                                            anodeycoord integer,\n",
    "                                            bnodexcoord integer,\n",
    "                                            bnodeycoord integer,\n",
    "                                            id serial) TABLESPACE pg_default''')\n",
    "    conn.execute(\"COMMIT\")                                            \n",
    "    conn.execute('''ALTER TABLE rl.abnodes OWNER to postgres''')\n",
    "    conn.execute(\"COMMIT\")\n",
    "    conn.execute('''INSERT INTO rl.abnodes (anodestopid, bnodestopid)\n",
    "                    SELECT AnodeStopID, BnodeStopID\n",
    "                    FROM rl.routelines1 \n",
    "                    GROUP BY  AnodeStopID, BnodeStopID''')\n",
    "    conn.execute(\"COMMIT\")\n",
    "    conn.execute('''UPDATE rl.abnodes\n",
    "                    SET anodexcoord = CAST(updanode.xcoord AS integer), anodeycoord = CAST(updanode.ycoord AS integer)\n",
    "                    FROM (SELECT * FROM rl.abnodes, rl.ptstops_temp WHERE anodestopid = naptanid) AS updanode\n",
    "                    WHERE updanode.id = abnodes.id''')\n",
    "    conn.execute(\"COMMIT\")\n",
    "    conn.execute('''UPDATE rl.abnodes\n",
    "                    SET bnodexcoord = CAST(updbnode.xcoord AS integer), bnodeycoord = CAST(updbnode.ycoord AS integer)\n",
    "                    FROM (SELECT * FROM rl.abnodes, rl.ptstops_temp WHERE bnodestopid = naptanid) AS updbnode\n",
    "                    WHERE updbnode.id = abnodes.id''')\n",
    "    conn.execute(\"COMMIT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def timestamp():\n",
    "    time = datetime.now()\n",
    "    time_hms = time.strftime(\"%H:%M:%S\")\n",
    "    return [time, time_hms]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data extraction from CIF files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------\n",
      "Current configuration\n",
      "Project data folder   :  D:/Routelines\n",
      "CIF data folder       :  D:/Routelines/data/\n",
      "CIF file              :  ATCO_Bus.cif\n",
      "PTStops tablename     :  ptstops\n",
      "-----------------------------------------------------------------------------------------------\n",
      "db server   :  localhost\n",
      "db port     :  5434\n",
      "db default  :  postgres\n",
      "database    :  routelinesuk\n",
      "schema      :  rl\n",
      "user        :  postgres\n",
      "password    :  softdesk\n",
      "-----------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "config_print('setup.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cif():\n",
    "    print(95*\"-\")\n",
    "    region =\"UK\"\n",
    "    t1, tp1 = timestamp()[0], timestamp()[1]\n",
    "    print(f\"Processing CIF file [{dir_cif+cif_file}] started at {tp1}\")\n",
    "    \n",
    "    cif_df = read_cif(dir_cif+cif_file)\n",
    "    t2, tp2 = timestamp()[0], timestamp()[1]\n",
    "    print(f\"Finished in {round((t2 - t1).total_seconds(),1)} seconds.\")\n",
    "    print(\"---\")\n",
    "    \n",
    "    print(\"Extracting PTStops (QB) data:\")\n",
    "    GetPtStops(conn, cif_df, pts_table)\n",
    "    t3, tp3 = timestamp()[0], timestamp()[1]\n",
    "    print(f\"Finished in {round((t3 - t2).total_seconds(),1)} seconds.\")\n",
    "    print(\"---\")\n",
    "    \n",
    "    GetRouteDataToSQL(conn, conn2, cif_df, region)\n",
    "    t4, tp4 = timestamp()[0], timestamp()[1]\n",
    "    print(f\"Finished in {round((t4 - t3).total_seconds(),1)} seconds.\")\n",
    "    print(\"---\")\n",
    "\n",
    "    ptstops_update(conn)\n",
    "    rl1_update(conn)\n",
    "    mt_update(conn)\n",
    "    \n",
    "    print(f\"Frequency calculating:\")\n",
    "    CreateFreq(conn)\n",
    "    ABsorter(conn)    \n",
    "    \n",
    "    print(\"Creation of 'ABNodesUK', 'RLFreqUK', 'RoutelinesUK'...\")\n",
    "    conn.execute('''CREATE TABLE rl.abnodesuk AS SELECT * FROM rl.abnodes''')\n",
    "    conn.execute(\"COMMIT\")  \n",
    "    conn.execute('''CREATE TABLE rl.rlfrequk AS SELECT * FROM rl.rlfreq''')\n",
    "    conn.execute(\"COMMIT\")  \n",
    "    conn.execute('''CREATE TABLE rl.routelinesuk AS SELECT bmrouteid, anodestopid, bnodestopid FROM rl.routelines1 GROUP BY bmrouteid, anodestopid, bnodestopid''')\n",
    "    conn.execute(\"COMMIT\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to database 'routelinesuk' on server 'localhost' !\n",
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Processing CIF file [D:/Routelines/data/ATCO_Bus.cif] started at 13:30:38\n",
      "-----------------------------------------------------------------------------------------------\n",
      "CIF file size is 13.08 MB\n",
      "Counting number of lines...\n",
      "390975 lines in the file!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db2d531b5134999b7a4f942c3bc70f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIF data imported!\n",
      "Finished in 0.3 seconds.\n",
      "---\n",
      "Extracting PTStops (QB) data:\n",
      "Extracting QB nodes in progress...\n",
      "QB nodes extracted: 8306\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c66e65bd0f42c689b749cf65606759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8306 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Finished in 0.8 seconds.\n",
      "---\n",
      "Data extraction from CIF to lists...\n",
      "Loading RouteLines1 to Pandas dataframe...\n",
      "Loading MainTable to Pandas dataframe...\n",
      "RouteLines1 size: 346526 rows\n",
      "MainTable size:   359128 rows\n",
      "Uploading RouteLines1 df to PostgreSQL...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b854e329f6d346bfac5705038c9a1c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading 'rl.routelines1' to PostgreSQL done!\n",
      "Uploading MainTable df to PostgreSQL...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e75e6e480c4feca57d960bdf341fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading 'rl.maintable' to PostgreSQL done!\n",
      "Finished in 6.5 seconds.\n",
      "---\n",
      "Updating 'PTStops_temp'...\n",
      "Updating RouteLines1 RouteID ...\n",
      "Updating Maintable RouteID...\n",
      "Frequency calculating:\n",
      "Freq. Calculations for mon...\n",
      "Freq. Calculations for tue...\n",
      "Freq. Calculations for wed...\n",
      "Freq. Calculations for thur...\n",
      "Freq. Calculations for fri...\n",
      "Freq. Calculations for sat...\n",
      "Freq. Calculations for sun...\n",
      "Creation of ABNodes and updating...\n",
      "Creation of 'ABNodesUK', 'RLFreqUK', 'RoutelinesUK'...\n"
     ]
    }
   ],
   "source": [
    "conn = db_connect(db_server, db_port, db_name, db_user, db_password)\n",
    "conn2 = connect(db_name, db_user, db_password, db_server, db_port)\n",
    "noc_table(conn, dir_cif)\n",
    "conn.execute('CREATE TABLE rl.ptstops_temp(naptanid text, xcoord text, ycoord text)')\n",
    "conn.execute(\"COMMIT\")\n",
    "cif()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red' style=\"font-size:30px\"><b>Done!</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MapBasic EA region calculations     : 03m:24sec\n",
    "# Python+SQLite EA region calculations: 00m:10sec  ~20x faster\n",
    "\n",
    "# MapBasic All regions calculations     : 4h:45m:00sec\n",
    "# Python+SQLite All regions calculations: 0h:17m:10sec  ~17x faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
